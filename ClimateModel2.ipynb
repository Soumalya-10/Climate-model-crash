{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Run</th>\n",
       "      <th>vconst_corr</th>\n",
       "      <th>vconst_2</th>\n",
       "      <th>vconst_3</th>\n",
       "      <th>vconst_4</th>\n",
       "      <th>vconst_5</th>\n",
       "      <th>vconst_7</th>\n",
       "      <th>ah_corr</th>\n",
       "      <th>ah_bolus</th>\n",
       "      <th>...</th>\n",
       "      <th>efficiency_factor</th>\n",
       "      <th>tidal_mix_max</th>\n",
       "      <th>vertical_decay_scale</th>\n",
       "      <th>convect_corr</th>\n",
       "      <th>bckgrnd_vdc1</th>\n",
       "      <th>bckgrnd_vdc_ban</th>\n",
       "      <th>bckgrnd_vdc_eq</th>\n",
       "      <th>bckgrnd_vdc_psim</th>\n",
       "      <th>Prandtl</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859036</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>0.298838</td>\n",
       "      <td>0.170521</td>\n",
       "      <td>0.735936</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245675</td>\n",
       "      <td>0.104226</td>\n",
       "      <td>0.869091</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.448620</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.796997</td>\n",
       "      <td>0.869893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.457728</td>\n",
       "      <td>0.359448</td>\n",
       "      <td>0.306957</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>0.934851</td>\n",
       "      <td>0.444572</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616870</td>\n",
       "      <td>0.975786</td>\n",
       "      <td>0.914344</td>\n",
       "      <td>0.845247</td>\n",
       "      <td>0.864152</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.356573</td>\n",
       "      <td>0.438447</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>0.517399</td>\n",
       "      <td>0.504993</td>\n",
       "      <td>0.618903</td>\n",
       "      <td>0.605571</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>0.195928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679355</td>\n",
       "      <td>0.803413</td>\n",
       "      <td>0.643995</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.924775</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.285636</td>\n",
       "      <td>0.365858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.104055</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.421837</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.490828</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471463</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>0.362751</td>\n",
       "      <td>0.912819</td>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.475987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.513199</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.844798</td>\n",
       "      <td>0.441502</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551543</td>\n",
       "      <td>0.743877</td>\n",
       "      <td>0.312349</td>\n",
       "      <td>0.650223</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.280098</td>\n",
       "      <td>0.132283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study  Run  vconst_corr  vconst_2  vconst_3  vconst_4  vconst_5  vconst_7  \\\n",
       "0      1    1     0.859036  0.927825  0.252866  0.298838  0.170521  0.735936   \n",
       "1      1    2     0.606041  0.457728  0.359448  0.306957  0.843331  0.934851   \n",
       "2      1    3     0.997600  0.373238  0.517399  0.504993  0.618903  0.605571   \n",
       "3      1    4     0.783408  0.104055  0.197533  0.421837  0.742056  0.490828   \n",
       "4      1    5     0.406250  0.513199  0.061812  0.635837  0.844798  0.441502   \n",
       "\n",
       "    ah_corr  ah_bolus  ...  efficiency_factor  tidal_mix_max  \\\n",
       "0  0.428325  0.567947  ...           0.245675       0.104226   \n",
       "1  0.444572  0.828015  ...           0.616870       0.975786   \n",
       "2  0.746225  0.195928  ...           0.679355       0.803413   \n",
       "3  0.005525  0.392123  ...           0.471463       0.597879   \n",
       "4  0.191926  0.487546  ...           0.551543       0.743877   \n",
       "\n",
       "   vertical_decay_scale  convect_corr  bckgrnd_vdc1  bckgrnd_vdc_ban  \\\n",
       "0              0.869091      0.997518      0.448620         0.307522   \n",
       "1              0.914344      0.845247      0.864152         0.346713   \n",
       "2              0.643995      0.718441      0.924775         0.315371   \n",
       "3              0.761659      0.362751      0.912819         0.977971   \n",
       "4              0.312349      0.650223      0.522261         0.043545   \n",
       "\n",
       "   bckgrnd_vdc_eq  bckgrnd_vdc_psim   Prandtl  outcome  \n",
       "0        0.858310          0.796997  0.869893        0  \n",
       "1        0.356573          0.438447  0.512256        1  \n",
       "2        0.250642          0.285636  0.365858        1  \n",
       "3        0.845921          0.699431  0.475987        1  \n",
       "4        0.376660          0.280098  0.132283        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"pop_failures.csv\",sep='\\s+')\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into input features and target variable\n",
    "X = data.drop(columns=['outcome'],axis=1)\n",
    "y = data[\"outcome\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "parameters = {\"max_depth\": [None, 5, 10, 20],\n",
    "              \"min_samples_split\": [2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "# Create the model\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Perform a grid search over the hyperparameters\n",
    "dtc_grid = GridSearchCV(dtc, parameters, cv=5)\n",
    "dtc_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Decision Tree Classifier Best Hyperparameters:\", dtc_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Hyperparameters: {'C': 10, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.91668003        nan 0.93282545        nan 0.96067896\n",
      "        nan 0.95137664]\n",
      "  warnings.warn(\n",
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "parameters = {\"C\": [0.1, 1, 10, 100],\n",
    "              \"penalty\": [\"l1\", \"l2\"]}\n",
    "\n",
    "# Create the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Perform a grid search over the hyperparameters\n",
    "lr_grid = GridSearchCV(lr, parameters, cv=5)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Logistic Regression Best Hyperparameters:\", lr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.9351851851851852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict the target variable for the testing data using the\n",
    "# best hyperparameters found during the grid search\n",
    "dtc_best = DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=10)\n",
    "dtc_best.fit(X_train, y_train)\n",
    "y_pred_dtc = dtc_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc_dtc = accuracy_score(y_test, y_pred_dtc)\n",
    "print(\"Decision Tree Classifier Accuracy:\", acc_dtc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9537037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soumalya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the testing data using the\n",
    "# best hyperparameters found during the grid search\n",
    "lr_best = LogisticRegression(C=10, penalty=\"l2\")\n",
    "lr_best.fit(X_train, y_train)\n",
    "y_pred_lr = lr_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", acc_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Perceptron: {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "Perceptron Accuracy: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the Perceptron model\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "params = {'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "          'alpha': [0.0001, 0.001, 0.01],\n",
    "          'max_iter': [1000, 2000, 3000],\n",
    "          'tol': [1e-3, 1e-4, 1e-5]}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "perceptron_grid = GridSearchCV(perceptron, param_grid=params, cv=5)\n",
    "perceptron_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found during the grid search\n",
    "print(\"Best Hyperparameters for Perceptron:\", perceptron_grid.best_params_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model to the training data\n",
    "perceptron_best = Perceptron(alpha=0.001, max_iter=1000, penalty='l2', tol=0.001)\n",
    "perceptron_best.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred_perceptron = perceptron_best.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
    "print(\"Perceptron Accuracy:\", acc_perceptron)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
